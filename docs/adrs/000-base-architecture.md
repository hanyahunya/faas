# ADR 000: Base Architecture

* **Status**: Superseded (by [ADR-001](./001-agent-async-pooling.md))
* **Date**: 2025-12-13
* **Technical Story**: FaaS 플랫폼의 초기 모델 설계 - 역할 분리, 스케일링 전략, 그리고 데이터 특성에 따른 저장소 선정

## 배경 및 문제점

서버리스(FaaS) 플랫폼을 구축함에 있어, 단순히 '실행된다'는 것을 넘어 확장성과 책임의 분리가 명확한 아키텍처가 필요합니다.
특히 다수의 요청이 동시에 들어올 때의 동시성 제어와, 성격이 다른 데이터(회원정보 vs 실행로그)를 효율적으로 처리할 수 있는 저장소 전략이 요구됩니다.

## 의사결정 요소

* **책임의 명확화**: 함수 실행의 주체는 `Main`이어야 하며, 다른 컴포넌트가 이 역할을 침범해서는 안 됨.
* **스케일링 효율성**: 컴퓨팅 리소스가 부족할 때, 전체 시스템이 아닌 필요한 부분(`Manager`)만 가볍게 확장 가능해야 함.
* **동시성 및 상태 관리**: 다수의 `Main` 서버가 존재하더라도 워커(컨테이너) 할당에 경쟁 상태(Race Condition)가 없어야 함.
* **데이터 일관성 및 성능**: 읽기가 많은 관리 데이터와 쓰기가 폭주하는 로그 데이터의 특성에 맞는 DB 선정 필요.

## 결정 사항

### 1. 함수 실행 책임의 집중
* **결정**: Cold Start 상황이라 하더라도 `Manager`가 직접 함수를 실행하지 않고, 생성된 컨테이너의 주소(`IP:Port`)를 `Main`에게 반환하여, **`Main`이 실행을 전담**하도록 합니다.
* **이유**: '함수 실행'이라는 핵심 비즈니스 로직의 책임을 `Main` 서버에 집중시켜, 트래픽 흐름을 일원화하고 모니터링을 용이하게 하기 위함입니다. Warm Start 시에는 불필요한 홉 없이 컨테이너로 직접 접근하여 오버헤드를 줄입니다.

### 2. Redis List를 활용한 워커 관리 및 오토 스케일링 (Atomic Worker Pool)
* **구조**: Redis에 `"func-a": ["IP:Port", ...]` 형태의 List로 관리합니다.
* **동작 방식**:
    * 요청 시 `LPOP`으로 워커를 꺼내오고, 실행 완료 후 `RPUSH`로 반환합니다.
    * **Atomic 보장**: Redis의 단일 스레드 특성을 이용해, 여러 `Main` 서버가 동시에 요청해도 하나의 컨테이너는 하나의 요청만 처리함을 보장합니다.
    * **스케일링 트리거**: `LPOP` 결과가 `Null`(비어있음)인 경우를 **리소스 부족 신호**로 간주하여 즉시 Cold Start(새 컨테이너 생성) 프로세스를 시작합니다. 이를 통해 자연스러운 오토 스케일링을 구현합니다.

### 3. 확장성을 고려한 Main - Manager 분리
* **결정**: 유저 요청을 받는 `Main` 서버와, 실제 컴퓨팅 노드를 관리하는 `Manager` 서버를 분리합니다.
* **이유**: 함수 실행 공간이 부족하여 서버를 증설해야 할 때, 무거운 로직이 포함된 `Main` 서버를 복제하는 것은 비효율적입니다. 컨테이너 생성/삭제 기능만 갖춘 가벼운 `Manager` 서버만 추가(Scale-out)하여 리소스 효율성을 극대화합니다.

### 4. 데이터 특성에 따른 DB 이원화
* **Auth 및 함수 관리 서버 (RDS - MySQL)**
    * **대상**: 사용자 정보, 함수 메타데이터, 빌드 정보 등.
    * **이유**: 데이터의 **정합성(Consistency)**이 매우 중요하며, 쓰기보다 **읽기(Read)** 트래픽이 월등히 많으므로 관계형 데이터베이스(MySQL)를 채택했습니다.
* **로깅 시스템 (NoSQL - MongoDB)**
    * **대상**: 함수 실행 결과 로그, 시스템 메트릭 등.
    * **이유**: **쓰기(Write)** 트래픽이 압도적으로 많으며, 로그 형식이 다양할 수 있습니다. 엄격한 트랜잭션보다는 빠른 쓰기 속도와 대용량 처리가 중요하므로 NoSQL(MongoDB)을 채택했습니다.

## 결과 및 장단점

### Positive (장점)
* **확실한 역할 분담**: `Main`은 실행, `Manager`는 자원 관리로 역할이 나뉘어 유지보수가 쉬움.
* **안전한 동시성 제어**: 별도의 락(Lock) 구현 없이 Redis List만으로 멀티 인스턴스 환경 대응 가능.
* **비용 효율적 확장**: 컴퓨팅 노드 추가 시 오버헤드가 적음.
* **DB 성능 최적화**: 각 데이터의 성격(Read/Write 비율, 정합성 중요도)에 맞는 최적의 저장소 사용.

### Negative (단점)
* **포트 고갈(Port Exhaustion)로 인한 동시성 제한 (치명적)**: 컨테이너마다 호스트의 TCP 포트를 할당하거나 연결을 유지해야 하므로, 서버 하드웨어 성능(CPU/RAM)이 아무리 좋아도 OS 네트워크 스택의 한계(Ephemeral Port 부족 등)로 인해 동시에 실행 가능한 최대 컨테이너 수가 제한됩니다.
* **Redis 강한 의존성**: 모든 상태 관리와 오토 스케일링 트리거가 Redis에 의존하므로 Redis 장애 시 서비스 전체가 중단될 위험이 있습니다. (이에 대한 대응으로 Master-Replica 복제 전략을 사용하여 고가용성을 확보할 예정입니다.)

## Architecture Flow Description
**Cold Start Flow**
<img width="1031" height="881" alt="cold_start_000" src="https://github.com/user-attachments/assets/bb14cf6f-dedc-461c-9964-05555511c740" />
(1) `func-a` 처리요청  
(2) Redis에 `"func-a": ["IP:Port"]` 있는지 조회하였으나 없음  
(3) Manager(`10.0.1.7`)에 `func-a` 함수실행공간 생성 요청  
(4) S3에서 `func-a`의 함수코드, 환경변수등 필요한 데이터를 가져옴  
(5) 데이터들을 적재후 컨테이너 생성  
(6) Main에 `func-a` 실행준비가 완료된 컨테이너의 위치(`10.0.1.7:30001`)를 전달  
(7) 직접 컨테이너의 주소(`10.0.1.7:30001`)에 접근하여 함수 실행, 응답을 처리  
(8) Redis에 `"func-a": ["10.0.1.7:30001"]`를 RPUSH  
(9) 로깅용 DB에 cold, warm여부 / RAM사용량 / 실행에 걸린시간등 로그를 기록  
  
**Warm Start Flow**
<img width="1031" height="881" alt="warm_start_000" src="https://github.com/user-attachments/assets/a1407b30-7627-4615-90ae-8e55a5fc035d" />
(1) `func-a` 처리요청  
(2) Redis에 `"func-a": ["IP:Port"]` 있는지 조회, `10.0.1.7:30001`를 LPOP  
(3) 직접 컨테이너의 주소(`10.0.1.7:30001`)에 접근하여 함수 실행, 응답을 처리  
(4) Redis에 `"func-a": ["10.0.1.7:30001"]`를 RPUSH  
(5) 로깅용 DB에 cold, warm여부 / RAM사용량 / 실행에 걸린시간등 로그를 기록  
